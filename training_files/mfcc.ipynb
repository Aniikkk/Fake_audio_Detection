{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pro 14\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Pro 14\\.pyenv\\pyenv-win\\versions\\3.11.8\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.7353 - val_accuracy: 0.8028 - val_loss: 0.4465\n",
      "Epoch 2/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7943 - loss: 0.4613 - val_accuracy: 0.8958 - val_loss: 0.2813\n",
      "Epoch 3/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.3490 - val_accuracy: 0.9069 - val_loss: 0.2303\n",
      "Epoch 4/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.3057 - val_accuracy: 0.9088 - val_loss: 0.2147\n",
      "Epoch 5/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.3096 - val_accuracy: 0.9370 - val_loss: 0.1611\n",
      "Epoch 6/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2703 - val_accuracy: 0.9352 - val_loss: 0.1683\n",
      "Epoch 7/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2634 - val_accuracy: 0.9398 - val_loss: 0.1503\n",
      "Epoch 8/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.2386 - val_accuracy: 0.9431 - val_loss: 0.1480\n",
      "Epoch 9/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2349 - val_accuracy: 0.9454 - val_loss: 0.1398\n",
      "Epoch 10/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2104 - val_accuracy: 0.9523 - val_loss: 0.1360\n",
      "Epoch 11/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.1885 - val_accuracy: 0.9435 - val_loss: 0.1405\n",
      "Epoch 12/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2019 - val_accuracy: 0.9477 - val_loss: 0.1258\n",
      "Epoch 13/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.1843 - val_accuracy: 0.9542 - val_loss: 0.1358\n",
      "Epoch 14/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.1916 - val_accuracy: 0.9537 - val_loss: 0.1280\n",
      "Epoch 15/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.1961 - val_accuracy: 0.9574 - val_loss: 0.1162\n",
      "Epoch 16/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.1897 - val_accuracy: 0.9509 - val_loss: 0.1210\n",
      "Epoch 17/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.1715 - val_accuracy: 0.9620 - val_loss: 0.1030\n",
      "Epoch 18/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.1664 - val_accuracy: 0.9551 - val_loss: 0.1227\n",
      "Epoch 19/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.1623 - val_accuracy: 0.9620 - val_loss: 0.1082\n",
      "Epoch 20/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1735 - val_accuracy: 0.9671 - val_loss: 0.0961\n",
      "Epoch 21/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.1698 - val_accuracy: 0.9602 - val_loss: 0.1149\n",
      "Epoch 22/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.1873 - val_accuracy: 0.9602 - val_loss: 0.1046\n",
      "Epoch 23/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9397 - loss: 0.1589 - val_accuracy: 0.9648 - val_loss: 0.0949\n",
      "Epoch 24/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.1672 - val_accuracy: 0.9648 - val_loss: 0.1028\n",
      "Epoch 25/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1541 - val_accuracy: 0.9676 - val_loss: 0.1020\n",
      "Epoch 26/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.1507 - val_accuracy: 0.9699 - val_loss: 0.0837\n",
      "Epoch 27/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1437 - val_accuracy: 0.9602 - val_loss: 0.1076\n",
      "Epoch 28/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1489 - val_accuracy: 0.9579 - val_loss: 0.1068\n",
      "Epoch 29/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9380 - loss: 0.1732 - val_accuracy: 0.9718 - val_loss: 0.0784\n",
      "Epoch 30/30\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1485 - val_accuracy: 0.9722 - val_loss: 0.0804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9729 - loss: 0.0824\n",
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../features/audio_features_mfcc.csv\")\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop(columns=['label', 'filename']).values  # Exclude label & filename\n",
    "y = df['label'].values\n",
    "\n",
    "# Load scaler and apply\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_shape = (X_train.shape[1],)\n",
    "num_labels = 2\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=input_shape, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)\n",
    "\n",
    "# Save model\n",
    "model.save(\"../models/audio_classification_model.h5\")\n",
    "\n",
    "# Evaluate model\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Prediction: Fake (Confidence: 100.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pro 14\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "def extract_features(file_path, sample_rate=16000, n_mfcc=40):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "        mfccs_features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs_features_scaled = np.mean(mfccs_features.T, axis=0)\n",
    "        return mfccs_features_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_audio(file_path, model_path=\"../models/audio_classification_model.h5\", scaler_path=\"scaler.pkl\"):\n",
    "    # Load model and scaler\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(file_path)\n",
    "    if features is None:\n",
    "        return \"Error: Could not process the audio file\"\n",
    "    \n",
    "    # Standardize features\n",
    "    features = scaler.transform([features])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(features)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_label] * 100\n",
    "    \n",
    "    label_map = {0: \"Real\", 1: \"Fake\"}\n",
    "    return f\"Prediction: {label_map[predicted_label]} (Confidence: {confidence:.2f}%)\"\n",
    "\n",
    "# Example usage\n",
    "file_path = \"../audio_files/p_35769890_526.wav\"  # Change to the path of your audio file\n",
    "print(predict_audio(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
